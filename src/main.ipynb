{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qji7gxIRzr_D"
      },
      "source": [
        "# **Full GPU-Accelerated Variational AutoEncoder Implementation in CUDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQBCQoJHzIN9"
      },
      "source": [
        "## Experimental Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9t8wuMq2woN"
      },
      "source": [
        "In this section we prepare and validate the experimental environment used\n",
        "for all subsequent benchmarks and analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63YL0obGzNQ8"
      },
      "source": [
        "We first verify that a CUDA-capable GPU is available and that the CUDA compiler (`nvcc`) is correctly installed.  \n",
        "This step ensures that the benchmarks will run on the expected hardware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKz_kz6MBa0J"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unTXbIgYzU1p"
      },
      "source": [
        "We clone the project repository from GitHub and place it in the working directory.\n",
        "This step recreates the exact codebase used for the experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K45c9LQ7BzLG"
      },
      "outputs": [],
      "source": [
        "REPO_URL=\"https://github.com/massimo-ruggiero/vae-cuda\"\n",
        "PROJECT_DIR=\"VAE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGD7WPyRCY8E",
        "outputId": "5b1ea97d-7525-4207-a302-571c5334a9af"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!rm -rf \"$PROJECT_DIR\"\n",
        "!git clone --depth 1 \"$REPO_URL\" \"$PROJECT_DIR\"\n",
        "%cd \"$PROJECT_DIR\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Ga-Oy1zcO_"
      },
      "source": [
        "We inspect the directory structure of the repository to verify that all expected\n",
        "modules and scripts are present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwshBjK9CcjI"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update -y >/dev/null\n",
        "!sudo apt-get install -y tree >/dev/null\n",
        "!tree -L 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EziMFeTZzh2z"
      },
      "source": [
        "The repository includes helper scripts for running the main training pipeline, the *micro* and *macro* benchmark suite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stkYEKr5CfdL",
        "outputId": "69c70f59-d423-4686-deb0-1a85d480f20e"
      },
      "outputs": [],
      "source": [
        "!ls -la scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7405GwBPzqhK"
      },
      "source": [
        "The VAE implementation expects the MNIST dataset to be provided in a custom\n",
        "binary format for fast loading during training and benchmarking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJh1WC1jMxPx",
        "outputId": "ae35ad8d-b75e-4697-9539-c7dd16cd52e7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "def save_to_bin(images, labels, filename):\n",
        "    images_flat = images.reshape(images.shape[0], -1).astype(np.uint8)\n",
        "    labels = labels.astype(np.uint8)\n",
        "\n",
        "    num_samples = images.shape[0]\n",
        "\n",
        "    header = np.array([num_samples], dtype=np.int32)\n",
        "\n",
        "    print(f\"Scrittura {filename}...\")\n",
        "    print(f\"  - Samples: {num_samples}\")\n",
        "    print(f\"  - Dimensioni Dati: {images_flat.shape}\")\n",
        "    print(f\"  - Dimensioni Labels: {labels.shape}\")\n",
        "\n",
        "    with open(filename, 'wb') as f:\n",
        "        header.tofile(f)\n",
        "        images_flat.tofile(f)\n",
        "        labels.tofile(f)\n",
        "\n",
        "    size_mb = os.path.getsize(filename) / (1024 * 1024)\n",
        "    print(f\"  -> Completato! ({size_mb:.2f} MB)\\n\")\n",
        "\n",
        "\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "    print(\"Cartella 'data/' creata.\")\n",
        "\n",
        "print(\"Scaricamento MNIST da Keras...\")\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Genera i file binari\n",
        "save_to_bin(x_train, y_train, 'data/train.bin')\n",
        "save_to_bin(x_test, y_test,  'data/test.bin')\n",
        "\n",
        "print(\"Tutto fatto. Ora puoi lanciare il programma C++.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Aue81QwyedQ"
      },
      "source": [
        "## End-to-End Sanity Check\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9mdRUQ821RM"
      },
      "source": [
        "Before running the full benchmark suite, we perform a quick end-to-end test to verify that:\n",
        "- the project compiles and runs correctly on the current GPU\n",
        "- training executes without runtime errors\n",
        "- the VAE produces a valid reconstruction\n",
        "- the sampling pipeline generates plausible outputs\n",
        "\n",
        "This step is not meant to optimize performance: it is a correctness + pipeline validation check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3ZuH5JVHF-3"
      },
      "outputs": [],
      "source": [
        "!chmod +x scripts/run_sanity_check.sh\n",
        "!bash scripts/run_sanity_check.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ednULfeUNLi4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "IMG_SIZE = 28\n",
        "IMG_PIXELS = IMG_SIZE * IMG_SIZE\n",
        "\n",
        "\n",
        "def load_raw_image(path: str) -> np.ndarray:\n",
        "    data = np.fromfile(path, dtype=np.float32)\n",
        "\n",
        "    if data.size != IMG_PIXELS:\n",
        "        raise ValueError(\n",
        "            f\"{path}: expected {IMG_PIXELS} values, found {data.size}\"\n",
        "        )\n",
        "\n",
        "    return data.reshape(IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "\n",
        "def show_reconstruction(original_path: str, reconstructed_path: str):\n",
        "    img_orig = load_raw_image(original_path)\n",
        "    img_recon = load_raw_image(reconstructed_path)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Original input\")\n",
        "    plt.imshow(img_orig, cmap=\"gray\", vmin=0, vmax=1)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"VAE reconstruction\")\n",
        "    plt.imshow(img_recon, cmap=\"gray\", vmin=0, vmax=1)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_sample(sample_path: str, title: str = \"VAE sample\"):\n",
        "    img = load_raw_image(sample_path)\n",
        "\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.title(title)\n",
        "    plt.imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-LEMnvOQULE"
      },
      "outputs": [],
      "source": [
        "print(\"üìÇ Loading raw images...\")\n",
        "\n",
        "try:\n",
        "    # --- paths ---\n",
        "    base_dir = Path(\"images/Warp Reduction\")\n",
        "    original = base_dir / \"original.raw\"\n",
        "    reconstructed = base_dir / \"reconstructed.raw\"\n",
        "\n",
        "    sample_0 = base_dir / \"sample_0.raw\"\n",
        "\n",
        "    # --- visualizations ---\n",
        "    show_reconstruction(original, reconstructed)\n",
        "    show_sample(sample_0, title=\"VAE sample\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(\"‚ùå File not found:\", e)\n",
        "    print(\"Make sure you have run the C++ program first.\")\n",
        "except ValueError as e:\n",
        "    print(\"‚ùå Data error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8dX9If41N9n"
      },
      "source": [
        "## Micro-Benchmark Suite Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efZGaxfJ23d2"
      },
      "source": [
        "After validating the end-to-end execution of the VAE pipeline, we run a dedicated\n",
        "micro-benchmark suite to evaluate the performance of individual CUDA kernels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icilUO8i1UsL"
      },
      "source": [
        "The micro-benchmark script supports a configurable output directory.\n",
        "\n",
        "- **Default output directory:** `results/`\n",
        "- **Custom output directory:** specified via the `--outdir <path>` option\n",
        "\n",
        "All benchmark results are stored as CSV files inside the selected directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bP0CrUzCg4M"
      },
      "outputs": [],
      "source": [
        "!chmod +x scripts/run_micro_bench.sh\n",
        "!bash scripts/run_micro_bench.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J27toaLLDSut"
      },
      "source": [
        "### Roofline Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb8Hto9ZFOwX"
      },
      "source": [
        "The roofline model provides an upper bound on the attainable performance of a kernel\n",
        "by relating **arithmetic intensity** (FLOPs per byte of memory traffic) to the\n",
        "hardware limits of the target architecture.\n",
        "\n",
        "Given a kernel with work $W$ (in FLOPs) and memory traffic $Q$ (in bytes),\n",
        "the arithmetic intensity is defined as:\n",
        "$$\n",
        "AI = \\frac{W}{Q}\n",
        "$$\n",
        "\n",
        "The attainable performance $P$ is bounded by:\n",
        "$$\n",
        "P = \\min \\left( \\pi,\\; \\beta \\times AI \\right)\n",
        "$$\n",
        "where:\n",
        "- $\\pi$ is the peak compute performance (GFLOPS),\n",
        "- $\\beta$ is the peak memory bandwidth (GB/s).\n",
        "\n",
        "The intersection of the two bounds defines the **ridge point**\n",
        "$AI = \\pi / \\beta$, which separates **memory-bound** from **compute-bound**\n",
        "execution regimes.\n",
        "\n",
        "In the following plot, each point represents the measured performance of a kernel\n",
        "implementation positioned according to its arithmetic intensity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfDWTpiCF-V6"
      },
      "source": [
        "**<font color=\"red\">‚ö†Ô∏è\n",
        "Kernels with zero arithmetic intensity perform no floating-point operations and therefore cannot be meaningfully positioned on the roofline in terms of GFLOPS.\n",
        "</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBD4_LnlDUKd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "def read_bench_csv(path: str | Path):\n",
        "    \"\"\"\n",
        "    Reads your CSV format:\n",
        "      # key=value\n",
        "      # key=value\n",
        "      op,strategy,... (real CSV header)\n",
        "      ...\n",
        "    Returns: (df, meta_dict)\n",
        "    \"\"\"\n",
        "    path = Path(path)\n",
        "    meta = {}\n",
        "\n",
        "    with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        pos = f.tell()\n",
        "        line = f.readline()\n",
        "        while line:\n",
        "            if line.startswith(\"#\"):\n",
        "                m = re.match(r\"#\\s*([A-Za-z0-9_]+)\\s*=\\s*(.*)\\s*$\", line.strip())\n",
        "                if m:\n",
        "                    k, v = m.group(1), m.group(2)\n",
        "                    try:\n",
        "                        meta[k] = float(v)\n",
        "                    except ValueError:\n",
        "                        meta[k] = v\n",
        "                pos = f.tell()\n",
        "                line = f.readline()\n",
        "            else:\n",
        "                f.seek(pos)\n",
        "                break\n",
        "\n",
        "    df = pd.read_csv(path, comment=\"#\")\n",
        "    return df, meta\n",
        "\n",
        "\n",
        "def plot_roofline_from_csv(\n",
        "    csv_paths,\n",
        "    strategy=\"NAIVE\",\n",
        "    ops=None,\n",
        "    title=\"Roofline\",\n",
        "    ai_limits=(1/32, 256),\n",
        "    perf_limits=None,\n",
        "    label_col=\"Kernel\",\n",
        "    figsize=(9, 6),\n",
        "):\n",
        "    \"\"\"\n",
        "    Draws a roofline plot in the same style as your reference image.\n",
        "    - black roofline\n",
        "    - thin dashed horizontal and diagonal guide lines\n",
        "    - red dashed vertical ridge line\n",
        "    - annotations: œÄ and Œ≤√óI\n",
        "    - legend includes ONLY points (kernels)\n",
        "    \"\"\"\n",
        "    dfs = []\n",
        "    metas = []\n",
        "    for p in csv_paths:\n",
        "        df, meta = read_bench_csv(p)\n",
        "        dfs.append(df)\n",
        "        metas.append(meta)\n",
        "    df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    meta0 = metas[0] if metas else {}\n",
        "    peak_gflops = float(meta0.get(\"peak_gflops_fp32\", 8100.0))\n",
        "    peak_bw     = float(meta0.get(\"peak_bandwidth_gbps\", 320.0))\n",
        "    ridge       = float(meta0.get(\"ridge_point\", peak_gflops / peak_bw))\n",
        "\n",
        "    # Filter strategy and ops\n",
        "    if \"strategy\" in df.columns:\n",
        "        df = df[df[\"strategy\"] == strategy]\n",
        "    if ops is not None and \"op\" in df.columns:\n",
        "        df = df[df[\"op\"].isin(ops)]\n",
        "\n",
        "    if \"flops\" in df.columns:\n",
        "        df = df[df[\"flops\"] > 0]\n",
        "    else:\n",
        "        raise ValueError(\"Column 'flops' not found: cannot filter zero-FLOP kernels.\")\n",
        "\n",
        "    # Need ai + gflops\n",
        "    required = {\"ai\", \"gflops\", label_col}\n",
        "    missing = required - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns in CSV(s): {missing}. Found: {list(df.columns)}\")\n",
        "\n",
        "    # Roofline curve\n",
        "    ai = np.logspace(np.log10(ai_limits[0]), np.log10(ai_limits[1]), 600)\n",
        "    roof = np.minimum(peak_gflops, peak_bw * ai)\n",
        "    ai_star = peak_gflops / peak_bw  # theoretical ridge from peaks (for the dashed diagonal)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    # Main roofline (thick)\n",
        "    plt.plot(ai, roof, color=\"black\", linewidth=2)\n",
        "\n",
        "    # Thin dashed guide lines like the paper figure:\n",
        "    # - horizontal at œÄ (peak compute)\n",
        "    plt.hlines(\n",
        "        peak_gflops, ai_limits[0], ai_limits[1],\n",
        "        colors=\"black\", linestyles=\"--\", linewidth=1, alpha=0.6\n",
        "    )\n",
        "\n",
        "    # - diagonal continuation beyond ridge (dashed)\n",
        "    ai_diag = np.logspace(np.log10(ai_star), np.log10(ai_limits[1]), 200)\n",
        "    plt.plot(ai_diag, peak_bw * ai_diag, color=\"black\", linestyle=\"--\", linewidth=1, alpha=0.6)\n",
        "\n",
        "    # Ridge point vertical line (red dashed)\n",
        "    plt.axvline(ridge, linestyle=\"--\", color=\"red\", linewidth=2)\n",
        "\n",
        "    # Scatter points (legend = points only)\n",
        "    handles, labels = [], []\n",
        "    for key, grp in df.groupby(label_col):\n",
        "        sc = plt.scatter(grp[\"ai\"], grp[\"gflops\"], s=70, marker=\"o\")\n",
        "        handles.append(sc)\n",
        "        labels.append(str(key))\n",
        "\n",
        "    # Scales + labels\n",
        "    plt.xscale(\"log\")\n",
        "    plt.yscale(\"log\")\n",
        "    plt.xlabel(\"Operational / Arithmetic Intensity [FLOP/byte]\")\n",
        "    plt.ylabel(\"Performance [GFLOP/s]\")\n",
        "    plt.title(f\"{title} ‚Äî {strategy}\")\n",
        "\n",
        "    if perf_limits is not None:\n",
        "        plt.ylim(perf_limits)\n",
        "    plt.xlim(ai_limits)\n",
        "\n",
        "    # Grid (subtle)\n",
        "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.30)\n",
        "\n",
        "    plt.text(ai_limits[1] / 3, peak_gflops * 1.03, r\"$\\pi$\", fontsize=18)\n",
        "\n",
        "    ai_txt = np.sqrt(ai_limits[0] * (peak_gflops / peak_bw))\n",
        "    y_txt = peak_bw * ai_txt\n",
        "    plt.text(ai_txt * 1.1, y_txt * 1.1, r\"$\\beta \\times I$\", fontsize=16, rotation=35)\n",
        "\n",
        "    if handles:\n",
        "        plt.legend(handles, labels, title=\"Kernels\", loc=\"lower right\", frameon=True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return {\"peak_gflops_fp32\": peak_gflops, \"peak_bandwidth_gbps\": peak_bw, \"ridge_point\": ridge}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhVXJQ77Dn5K"
      },
      "outputs": [],
      "source": [
        "meta = plot_roofline_from_csv(\n",
        "    csv_paths=[\n",
        "        \"results/micro_bench/csv/bench_linalg.csv\",\n",
        "        \"results/micro_bench/csv/bench_activations.csv\",\n",
        "        \"results/micro_bench/csv/bench_loss.csv\",\n",
        "        \"results/micro_bench/csv/bench_reparam.csv\",\n",
        "        \"results/micro_bench/csv/bench_optimizers.csv\",\n",
        "    ],\n",
        "    strategy=\"NAIVE\",\n",
        "    title=\"Roofline\",\n",
        "    ai_limits=(1/64, 256),\n",
        "    perf_limits=(50, 20000),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNl7g_JJ1ZNO"
      },
      "source": [
        "## Macro-Benchmatk Suite Execution"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
